---
title: "Take-home Exercise 3"
description: |
  This take home exercise aims to explain factors affecting resale prices of public housing in Singapore by building hedonic pricing models using appropriate GWR methods.
author:
  - name: Genice Goh
    url: {}
date: 11-05-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# 1.0 Introduction

Housing price is affected by a variety of factors, including global factors such as the general economy of a country or property specific factors such as structural variables related to the property and locational variables related to the neighbourhood.

Hedonic pricing model is used to examine the effect of housing factors as on property price. However, this method fails to take into consideration that spatial autocorrelation and spatial heterogeneity exist in housing transaction data, which could lead to biased results (Anselin 1998). In view of this limitation, Geographical Weighted Regression (GWR) was introduced to calibrate hedonic price models for housing.

As such, we will be building hedonic pricing models to explain factors affecting the resale prices of public housing in Singapore using appropriate GWR methods.

## 1.1 The Data 

The data sets used for this analysis include:

- Resale Flat Prices from [data.gov.sg]("https://data.gov.sg/dataset/resale-flat-prices")
- Master Plan 2014 Subzone Boundary (Web) from [data.gov.sg](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web?resource_id=1c6b586b-61ca-45a9-b704-df4c9057fbd6)
- Eldercare centres, hawker centres, parks, supermarkets, kindergartens and childcare centres extracted from SLA OneMap Service by using [onemapsgapi](https://cran.r-project.org/web/packages/onemapsgapi/index.html)
- Train Station from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html)
- Bus Stop Location from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html)
- School Directory and Information from [data.gov.sg](https://data.gov.sg/dataset/school-directory-and-information)
- Shopping Mall from [ValaryLim](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/mall_coordinates_updated.csv)

# 1.2 Installing and Loading Packages

The packages used for this analysis include:

- **sf**, **spdep**: used for handling of geospatial data
- **tidyverse** (**readr**, **ggplot2**, **dplyr**): mainly used for wrangling attribute data 
- **tmap**: used to prepare cartographic quality choropleth maps
- **coorplot**, **ggpubr**: used for multivariate data visualisation and analysis
- **olsrr**: used to build ordinary least squares regression models
- **GWmodel**: used for geospatial statistical modelling
- **httr**: used to make API calls 
- **units**, **matrixStats**: used for matrix manipulation

```{r echo=TRUE}
packages = c('olsrr', 'corrplot', 'ggpubr', 'sf', 'spdep', 'GWmodel', 'tmap', 'tidyverse', 'httr', 'units', 'matrixStats')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# 2.0 Geospatial Data

## 2.1 Importing Geospatial Data

*st_read()* of **sf** package is used to import the geospatial data, which is in **shapefile** format.

```{r echo=TRUE}
mrt_sf <- st_read(dsn="data/geospatial",
               layer="MRTLRTStnPtt")

bus_sf <- st_read(dsn="data/geospatial",
               layer="BusStop")

mpsz_sf <- st_read(dsn="data/geospatial",
               layer="MP14_SUBZONE_WEB_PL")
```

From the output message, we can see that:

- There are **185 point features** and **3 fields** in the `mrt_sf` sf data frame.
- There are **5156 point features** and **3 fields** in the `bus_sf` sf data frame.
- There are **323 multi-polygon features** and **15 fields** in the `mpsz_sf` sf data frame.
- SVY21 is the **Projected Coordinates Reference System** for the data frames. 

## 2.2 Data Preprocessing

Before we visualise the geospatial data, we will need to conduct data preprocessing to ensure that there are no invalid geometries and missing values.

### 2.2.1 Invalid Geometries

```{r echo=TRUE}
length(which(st_is_valid(mrt_sf) == FALSE))
length(which(st_is_valid(bus_sf) == FALSE))
length(which(st_is_valid(mpsz_sf) == FALSE))
```

There are **no invalid geometries** in both `mrt_sf`and `bus_sf` data frames while the `mpsz_sf` data frame contains **9 invalid geometries**. We will now proceed to remove the invalid geometries in the `mpsz_sf` data frame.

```{r echo=TRUE}
mpsz_sf <- st_make_valid(mpsz_sf)

# Check again for invalid geometries
length(which(st_is_valid(mpsz_sf) == FALSE))
```

### 2.2.2 Missing Values

```{r echo=TRUE}
mrt_sf[rowSums(is.na(mrt_sf))!=0,]
bus_sf[rowSums(is.na(bus_sf))!=0,]
mpsz_sf[rowSums(is.na(mpsz_sf))!=0,]
```

We can see that there is **1 observation with missing values** in the `bus_sf` data frame. We will remove it because another bus stop of the same **BUS_ROOF_N** is found after further data exploration.

```{r echo=TRUE, eval=TRUE}
bus_sf <- bus_sf[!rowSums(is.na(bus_sf))!=0,]

# Check again for missing values
bus_sf[rowSums(is.na(bus_sf))!=0,]
```

### 2.2.3 Duplicated Values

```{r echo=TRUE, eval=TRUE}
mrt_sf[duplicated(mrt_sf$STN_NAME),]
bus_sf[duplicated(bus_sf$BUS_STOP_N),]
mpsz_sf[duplicated(mpsz_sf$SUBZONE_C),]
```

We can observe that there are **19** and **13** **duplicated observations** in the `mrt_sf` and `bus_sf` data frames respectively, while there are none in the `mpsz_sf` data frame. We will proceed to remove the duplicated observations.

```{r echo=TRUE, eval=TRUE}
mrt_sf <- mrt_sf[!duplicated(mrt_sf$STN_NAME),]
bus_sf <- bus_sf[!duplicated(bus_sf$BUS_STOP_N),]

# Check again for duplicates
mrt_sf[duplicated(mrt_sf$STN_NAME),]
bus_sf[duplicated(bus_sf$BUS_STOP_N),]
```

## 2.3 Verify Coordinate Reference System

We will first need to retrieve the coordinate reference system for verification. *st_crs()* of **sf** package is used to do this. 

```{r echo=TRUE}
st_crs(mrt_sf)
st_crs(bus_sf)
st_crs(mpsz_sf)
```

From the output messages, we can observe that the EPSG code for the data frames is currently **9001**. This is **wrong** because the EPSG code of projection coordinate system SVY21 is supposed to be **3414**, instead of 9001. 

*st_set_crs()* of **sf** package is therefore used to assign the correct EPSG code for the data frames.

```{r echo=TRUE}
mrt_sf <- st_set_crs(mrt_sf, 3414)
bus_sf <- st_set_crs(bus_sf, 3414)
mpsz_sf <- st_set_crs(mpsz_sf, 3414)
```

We will now use *st_crs()* of **sf** package to retrieve the coordinate reference system again.

```{r echo=TRUE}
st_crs(mrt_sf)
st_crs(bus_sf)
st_crs(mpsz_sf)
```

The EPSG code is now correctly assigned for all sf data frames!!

## 2.4 Visualising Geospatial Data

It is useful to plot a map to visualise the geospatial data, so that we can easily get a preliminary look at the spatial patterns. 

```{r echo=TRUE}
tmap_mode('view')

tm_shape(mrt_sf) +
  tm_dots(col="red") +
tm_shape(bus_sf) + 
  tm_dots(col="blue")
```

```{r}
tmap_mode('plot')
```

If we look closely, we can see that there are 5 bus stops outside of Singapore's boundary (46211, 46219, 46239, 46609, 47701). As we are able to travel to and fro Johor Bahru with specific buses, there are designated bus stops located at Johor Bahru.

As such, we should remove these bus stops before proceeding with our analysis. 

## 2.5 Further Data Preprocessing

In this section, we will proceed to remove the bus stops identified earlier.

### 2.5.1 Inspect the specific bus stops

```{r echo=TRUE, eval=TRUE}
omit_bus <- list(46211, 46219, 46239, 46609, 47701)
bus_sf[bus_sf$BUS_STOP_N %in% omit_bus,]
```

We can observe that the location descriptions of these bus stops indeed indicate that they are situated in Johor Bahru. We will therefore need to remove them.

```{r echo=TRUE, eval=TRUE}
bus_sf <- bus_sf[!bus_sf$BUS_STOP_N %in% omit_bus,]

# Check again if we have removed successfully
bus_sf[bus_sf$BUS_STOP_N %in% omit_bus,]
```

# 3.0 Aspatial Data

## 3.1 Obtaining Aspatial Data

We will be making use of the package [**onemapsgapi**](https://cran.r-project.org/web/packages/onemapsgapi/onemapsgapi.pdf) to query the required data sets from OneMap API. We will then save these data sets in CSV format. 

```{r echo=TRUE, eval=FALSE}
library(onemapsgapi)

token <- "<insert your token here>"

data <- list("eldercare", "hawkercentre", "relaxsg", "supermarkets", "kindergartens", "childcare")

for (d in data) {
  df <- get_theme(token, d)
  write_csv(df, str_replace("data/aspatial/df.csv", "df", d))
}
```

## 3.2 Importing Aspatial Data

*read_csv()* of **readr** package is used to import the CSV files. The outputs are **tibble** data frames. 

```{r echo=TRUE, eval=FALSE}
eldercare = read_csv("data/aspatial/eldercare.csv")
hawker = read_csv("data/aspatial/hawkercentre.csv")
park = read_csv("data/aspatial/relaxsg.csv")
supermarket = read_csv("data/aspatial/supermarkets.csv")
kindergarten = read_csv("data/aspatial/kindergartens.csv")
childcare = read_csv("data/aspatial/childcare.csv")
school = read_csv("data/aspatial/schools.csv")
mall = read_csv("data/aspatial/shopping-mall.csv")
flat_resale = read_csv("data/aspatial/resale-flat-prices.csv")
```

It is also important to understand the data that we are working with. *glimpse()* of **dplyr** package is therefore used to perform exploratory data analysis. 

```{r echo=TRUE, eval=FALSE}
glimpse(eldercare)
glimpse(hawker)
glimpse(park)
glimpse(supermarket)
glimpse(kindergarten)
glimpse(childcare)
glimpse(school)
glimpse(mall)
glimpse(flat_resale)
```

## 3.3 Data Preparation

We will proceed to prepare the data such that they can be used later for the preparation of independent variables. The steps taken include:

- Removing redundant columns (if necessary)
- Filtering the data according to specified conditions (if necessary)
- Creation of new data frames (if necessary)

```{r echo=TRUE, eval=FALSE}
# remove redundant columns for eldercare dataset
eldercare <- eldercare %>%
  select(c(1, 4:5))

# remove redundant columns for hawker dataset
hawker <- hawker %>%
  select(c(1, 14:15))

# remove redundant columns for park dataset
park <- park %>%
  select(c(1, 8:9))

# remove redundant columns for supermarket dataset
supermarket <- supermarket %>%
  select(c(1, 7:8))

# remove redundant columns for kindergarten dataset
kindergarten <- kindergarten %>%
  select(c(1, 5:6))

# remove redundant columns for childcare dataset
childcare <- childcare %>%
  select(c(1, 5:6))

# filter out primary schools; remove redundant columns 
prischool <- school %>%
  filter(mainlevel_code == "PRIMARY") %>% 
  select(c(1, 3:4, 25,27))

# filter out 4-room flats with transaction period from 01-Jan-19 to 30-Sep-20
flat_resale <- flat_resale %>% 
  filter(flat_type == "4 ROOM") %>%
  filter(month >= "2019-01" & month < "2020-10")
```

## 3.4 Data Preprocessing

We will need to conduct data preprocessing to ensure that there are no NA values in all data frames.

### 3.4.1 NA Values

```{r echo=TRUE, eval=FALSE}
eldercare[rowSums(is.na(eldercare))!=0,]
hawker[rowSums(is.na(hawker))!=0,]
park[rowSums(is.na(park))!=0,]
supermarket[rowSums(is.na(supermarket))!=0,]
kindergarten[rowSums(is.na(kindergarten))!=0,]
childcare[rowSums(is.na(childcare))!=0,]
prischool[rowSums(is.na(prischool))!=0,]
mall[rowSums(is.na(mall))!=0,]
flat_resale[rowSums(is.na(flat_resale))!=0,]
```

There are no NA values in all the data frames. 

## 3.5 Geocoding for Aspatial Data

After exploratory data analysis performed earlier, it is found that `prischool` and `flat_resale` data frames do not have **Lat** and **Lng** columns. These columns are required for the preparation of the independent variables later. We therefore need to use [OneMap API](https://cran.r-project.org/web/packages/onemapsgapi/index.html) to geocode the coordinates columns. 

### 3.5.1 Create Address Column

We first need to create an address column for the `flat_resale` data frame since the address data is currently split into 2 columns block and street name respectively.

*unite()* of **dpylr** package is used to concatenate the 2 columns. 

```{r echo=TRUE, eval=FALSE}
flat_resale <- flat_resale %>%
  unite("address", block:street_name, sep= " ")
```

### 3.5.2 Rename ST. to SAINT

We alo observe that some addresses in the the `flat_resale` data frame start with **"ST."**. It is found later that this will pose problems during geocoding. As a result, we will need to rename **"ST."** to its full version **"SAINT"**.

```{r echo=TRUE, eval=FALSE}
flat_resale$address <- gsub("ST\\.", "SAINT", flat_resale$address)
```

### 3.5.3 Geocoding Function

In this function, the input variable **address** is passed in as a search value in the query to the API. The output is then converted to a data frame, where we only choose to retain the **Latitude** and **Longitude** columns. These 2 columns are returned as the output.  

```{r echo=TRUE, eval=FALSE}
geocode <- function(address) {

  url <- "https://developers.onemap.sg/commonapi/search"

  query <- list("searchVal" = address, "returnGeom" = "Y",
                "getAddrDetails" = "N", "pageNum" = "1")

  res <- GET(url, query = query, verbose())

  output <- content(res) %>%
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

### 3.5.4 Geocoding for Primary Schools

We will now loop through each row of the `prischool` data frame and implement the **geocode** function. The output is saved as 2 new columns **Lat** and **Lng**.

```{r echo=TRUE, eval=FALSE}
prischool$Lat <- 0
prischool$Lng <- 0

for (i in 1:nrow(prischool)) {
  output <- geocode(prischool$postal_code[i])
  
  prischool$Lat[i] <- output$results.LATITUDE
  prischool$Lng[i] <- output$results.LONGITUDE
}
```

### 3.5.5 Geocoding for Resale Flat Prices

We will now loop through each row of the `flat_resale` data frame and implement the **geocode** function. The output is saved as 2 new columns **Lat** and **Lng**.

```{r echo=TRUE, eval=FALSE}
flat_resale$Lat <- 0
flat_resale$Lng <- 0

for (i in 1:nrow(flat_resale)) {
  output <- geocode(flat_resale$address[i])
  
  flat_resale$Lat[i] <- output$results.LATITUDE
  flat_resale$Lng[i] <- output$results.LONGITUDE
}
```

## 3.6 Structural Factor Preparation

### 3.6.1 Floor Level

We need to conduct dummy coding on the **storey_range** variable for us to use it in model later. We will first look at the individual storey-range values for us to get a rough idea on the number of columns that will be produced. 

```{r echo=TRUE, eval=FALSE}
unique(flat_resale$storey_range)
```

We observed that there are **17 storey range categories**.

To conduct dummy coding, we will be using *pivot_wider()* of **dplyr** package to create duplicate variables representing every store-range. If the obeservation belongs to the storey-range, the value will be 1. The value will be 0 otherwise.   

```{r echo=TRUE, eval=FALSE}
flat_resale <- flat_resale %>%
  pivot_wider(names_from = storey_range, values_from = storey_range, 
              values_fn = list(storey_range = ~1), values_fill = 0) 
```

### 3.6.2 Remaining Lease

We need to convert the **remaining_lease** column from string to numeric format to use in the model later. We will first split the string within the column and take the value(s) of the year and month. We will then calculate the remaining lease in years and replace the original value. 

```{r echo=TRUE, eval=FALSE}
str_list <- str_split(flat_resale$remaining_lease, " ")

for (i in 1:length(str_list)) {
  if (length(unlist(str_list[i])) > 2) {
      year <- as.numeric(unlist(str_list[i])[1])
      month <- as.numeric(unlist(str_list[i])[3])
      flat_resale$remaining_lease[i] <- year + round(month/12, 2)
  }
  else {
    year <- as.numeric(unlist(str_list[i])[1])
    flat_resale$remaining_lease[i] <- year
  }
}
```

## 3.7 Locational Variable Preparation

### 3.7.1 Good Pri Sch Variable Preparation

We need to filter out good primary schools and save it as variable **goodprischool** for it to be used in the model. Good primary schools are defined to be Special Assistance Programme (SAP) primary schools or primary schools with the Gifted Education Programme (GEP). 

```{r echo=TRUE, eval=FALSE}
gdprischool <- prischool %>%
  filter(sap_ind == "Yes" | gifted_ind == "Yes")
```

### 3.7.2 CBD Variable Preparation

The Central Business District (CBD) is in Downtown Core, located in the southwest part of Singapore. We will therefore take the coordinates of Downtown Core to be the coordinates of the CBD and convert it into a **sf** data frame.

```{r echo=TRUE, eval=FALSE}
lat <- 1.287953
long <- 103.851784

cbd_sf <- data.frame(lat, long) %>%
  st_as_sf(coords = c("long", "lat"), crs=4326) %>%
  st_transform(crs=3414)
```

### 3.7.3 Convert Datasets to sf

We need to convert the data sets into **sf** data frames for us to calculate the proximity distance matrices. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- st_as_sf(flat_resale, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

eldercare_sf <- st_as_sf(eldercare, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

hawker_sf <- st_as_sf(hawker, 
                      coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

park_sf <- st_as_sf(park, 
                    coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

gdprischool_sf <- st_as_sf(gdprischool, 
                           coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

mall_sf <- st_as_sf(mall, 
                    coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs = 3414)

supermarket_sf <- st_as_sf(supermarket, 
                           coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

kindergarten_sf <- st_as_sf(kindergarten, 
                            coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

childcare_sf <- st_as_sf(childcare, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

prischool_sf <- st_as_sf(prischool, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)
```

### 3.7.4 Proximity Distance Calculation

This function computes the distance to the nearest facility. *st_distance()* of **sf** package is used to compute the distance between all flats and the respective facilities. *rowMins()* of **matrixStats** is then used to take the shortest distance within each row in the output matrix. The values will be appended to the data frame as a new column. 
  
```{r echo=TRUE, eval=FALSE}
proximity <- function(df1, df2, varname) {
  
  matrix <- st_distance(df1, df2) %>%
    drop_units()
  
  df1[,varname] <- rowMins(matrix)
  
  return(df1)
}
```

We will now implement the **proximity** function to the required variables. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- proximity(flat_resale_sf, cbd_sf, "PROX_CBD") %>%
  proximity(., eldercare_sf, "PROX_EC") %>%
  proximity(., hawker_sf, "PROX_HA") %>%
  proximity(., mrt_sf, "PROX_MRT") %>%
  proximity(., park_sf, "PROX_PARK") %>%
  proximity(., gdprischool_sf, "PROX_GDPRI") %>%
  proximity(., mall_sf, "PROX_MALL") %>%
  proximity(., supermarket_sf, "PROX_SUP")
```

### 3.7.5 Facility Count within Radius Calculation

This function computes the facility count within a radius. Similarly, *st_distance()* of **sf** package is used to compute the distance between all flats and the respective facilities. *rowSums()* of **dplyr** is then used to count the observations with distances below the defined radius. The values will be appended to the data frame as a new column. 

```{r echo=TRUE, eval=FALSE}
num_radius <- function(df1, df2, varname, radius) {
  
  matrix <- st_distance(df1, df2) %>%
    drop_units() %>%
    as.data.frame()
  
  df1[,varname] <- rowSums(matrix <= radius)
  
  return(df1)
}
```

We will now implement the **num_radius** function to the required variables. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- num_radius(flat_resale_sf, kindergarten_sf, 
                             "NUM_KIN", 350) %>%
  num_radius(., childcare_sf, "NUM_CC", 350) %>%
  num_radius(., bus_sf, "NUM_STOP", 350) %>%
  num_radius(., prischool_sf, "NUM_PRI", 1000)
```

## 3.8 Saving the Dataset

Before saving the dataset, we will remove the redundant columns, rename the columns to shorter forms and relocate the **price** columns to the front of the data frame. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- flat_resale_sf %>%
  select(5, 8, 9, 10:39) %>%
  rename("AREA_SQM" = "floor_area_sqm", "LEASE_YRS" = "remaining_lease", 
         "PRICE"= "resale_price") %>%
  relocate(`PRICE`)
```

We can now save the final flat resale price data set as a **SHP** file using *st_write* of **sf** package.

```{r echo=TRUE, eval=FALSE}
st_write(flat_resale_sf, "data/geospatial/resale-flat-prices-final.shp")
```

# 4.0 EDA

## 4.1 Import Full Dataset

*st_read()* of **sf** package is used to import the final data set, which is in **shapefile** format.

```{r echo=TRUE}
flat_resale_sf <- st_read(dsn="data/geospatial",
                          layer="resale-flat-prices-final")
```

## 4.2 EDA using statistical graphs

### 4.2.1 Dependent Variable 

We can plot the distribution of **PRICE** using a histogram as shown below.

```{r echo=TRUE}
ggplot(data=flat_resale_sf, aes(x=`PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

The figure above reveals a slightly **right skewed** distribution. This means that more HDB flats were transacted at **relative lower prices**.

Statistically, the skewed distribution can be **normalised** using **log transformation**. *mutate()* of **dplyr** package is used to derive a new variable called **LOG_PRICE** using a log transformation on the variable **PRICE**.

```{r echo=TRUE}
flat_resale_sf <- flat_resale_sf %>%
  mutate(`LOG_PRICE` = log(PRICE)) %>%
  relocate(`LOG_PRICE`, .after = `PRICE`)
```

We can now plot the distribution of **LOG_PRICE**.

```{r echo=TRUE}
ggplot(data=flat_resale_sf, aes(x=`LOG_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

### 4.2.2 Independent Variables

It is found that the **LEASE_YRS** column is still in string format. We will convert it to numeric format for us to conduct EDA and to input into the model later. 

```{r echo=TRUE}
flat_resale_sf$LEASE_YRS <- as.numeric(flat_resale_sf$LEASE_YRS)
```

We will now draw multiple histograms to show multiple distributions of the independent variables. This is done using *ggarrange()* of **ggpubr** package.

```{r echo=TRUE, fig.width=10, fig.height=8}
AREA_SQM <- ggplot(data=flat_resale_sf, aes(x= `AREA_SQM`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

LEASE_YRS <- ggplot(data=flat_resale_sf, aes(x= `LEASE_YRS`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=flat_resale_sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_EC <- ggplot(data=flat_resale_sf, aes(x= `PROX_EC`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER <- ggplot(data=flat_resale_sf, aes(x= `PROX_HA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=flat_resale_sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=flat_resale_sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_GDPRI <- ggplot(data=flat_resale_sf, aes(x= `PROX_GDPRI`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MALL <- ggplot(data=flat_resale_sf, aes(x= `PROX_MALL`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_SUP <- ggplot(data=flat_resale_sf, aes(x= `PROX_SUP`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_KIN <- ggplot(data=flat_resale_sf, aes(x= `NUM_KIN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_CC <- ggplot(data=flat_resale_sf, aes(x= `NUM_CC`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_STOP <- ggplot(data=flat_resale_sf, aes(x= `NUM_STOP`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_PRI <- ggplot(data=flat_resale_sf, aes(x= `NUM_PRI`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, LEASE_YRS, PROX_CBD, PROX_EC, PROX_HAWKER, PROX_MRT, PROX_PARK, PROX_GDPRI, PROX_MALL, PROX_SUP, NUM_KIN, NUM_CC, NUM_STOP, NUM_PRI, ncol = 3, nrow = 5)
```

We can observe that the distribution of the **majority** of the independent variables are **right skewed**, while variables such as **LEASE_YRS** and **PROX_CBD** are slightly **left skewed**.

## 4.3 EDA using statistical point map

We want to reveal the geospatial distribution flat resale prices (i.e. **dependent** variable) in Singapore using the **tmap** package.

```{r echo=TRUE}
tmap_mode("view")

tm_shape(mpsz_sf)+
  tm_polygons() +
tm_shape(flat_resale_sf) +  
  tm_dots(col = "PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode('plot')
```

From the map, we can observe that flats with **higher resale prices** are **more concentrated in the central area** of Singapore. 

# 5.0 Hedonic Price Modelling

We will be building the hedonic pricing model using both multiple linear regression method and appropriate GWR methods. The independent variables we are looking at include:

- Structural factors
  - Area of the unit
  - Floor level
  - Remaining lease
- Locational factors
  - Proximity to CBD
  - Proximity to eldercare centres
  - Proximity to hawker centres
  - Proximity to MRT
  - Proximity to parks
  - Proximity to good primary schools
  - Proximity to shopping malls
  - Proximity to supermarkets
  - No. of kindergartens within 350m
  - No. of childcare centres within 350m
  - No. of bus stops within 350m
  - No. of primary schools within 1km

## 5.1 Multiple Linear Regression Method

### 5.1.1 Visualising the relationships of the independent variables

Before building a multiple regression model, it is important to ensure that the **independent variables** used are **not highly correlated to each other**, which will cause the quality of the model to be compromised.

**Correlation matrix** is commonly used to visualise the relationships between the independent variables. **corrplot** package will be used to plot a scatterplot matrix of the relationship between the independent variables.

```{r echo=TRUE}
flat_resale <- flat_resale_sf %>%
  st_set_geometry(NULL)
```

```{r echo=TRUE, fig.width=18, fig.height=14}
corrplot(cor(flat_resale[, 3:33]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

From the scatterplot matrix, it is clear that **PROX_GDPRI** is **highly correlated** to **PROX_CBD**. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, **PROX_CBD** is **excluded** in the subsequent model building.

### 5.1.2 Building the Hedonic Pricing Model

*lm()* is used to calibrate the multiple linear regression model.

```{r echo=TRUE}
flat_mlr <- lm(formula = PRICE ~ AREA_SQM + LEASE_YRS + X01.TO.03 + X04.TO.06 + X07.TO.09 + X10.TO.12 + X13.TO.15 + X16.TO.18 + X19.TO.21 + X22.TO.24 + X25.TO.27 + X28.TO.30 + X31.TO.33 + X34.TO.36 + X37.TO.39 + X40.TO.42 + X43.TO.45 + X46.TO.48 + X49.TO.51 + PROX_EC + PROX_HA + PROX_MRT + PROX_GDPRI + PROX_MALL  + PROX_SUP + NUM_KIN + NUM_CC + NUM_STOP + NUM_PRI, data=flat_resale_sf)

summary(flat_mlr)
```

We can observe that not all the independent variables are statistically significant. We will therefore revise the model by removing those variables which are not statistically significant.

```{r echo=TRUE}
flat_mlr1 <- lm(formula = PRICE ~ AREA_SQM + LEASE_YRS + X01.TO.03 + X04.TO.06 + X07.TO.09 + X10.TO.12 + X13.TO.15 + X25.TO.27 + X28.TO.30 + X31.TO.33 + X34.TO.36 + X37.TO.39 + X40.TO.42 + X43.TO.45 + X46.TO.48 + X49.TO.51 + PROX_EC + PROX_HA + PROX_MRT + PROX_GDPRI + PROX_MALL  + PROX_SUP + NUM_KIN + NUM_CC + NUM_STOP + NUM_PRI, data=flat_resale_sf)

ols_regress(flat_mlr1)
```

### 5.1.3 Testing Assumptions of Linear Regression Models

We need to fulfill the 4 following assumptions to perform regression modelling on spatial data:
  
  - The residuals are uncorrelated with each other.
  - The relationship between the dependent variable and independent variables are approximately linear.
  - The residuals are assumed to be normally distributed.
  - The residuals are not distributed at random over geographical space.
  
#### 5.1.3.1 Test for Multi-collinearity

*ols_vif_tol()* of **olsrr** package is used to test if there are signs of **multi-collinearity**.

```{r echo=TRUE}
ols_vif_tol(flat_mlr1)
```

Since the **VIF** of the independent variables are **less than 10**, we can safely conclude that there are **no signs of multi-collinearity** among the independent variables.

#### 5.1.3.2 Test for Non-Linearity

*ols_plot_resid_fit()* of **olsrr** package is used to perform the **linearity** assumption test.

```{r echo=TRUE}
ols_plot_resid_fit(flat_mlr1)
```

The figure above reveals that **most of the data points are scattered around the 0 line**, we can therefore safely conclude that the relationships between the dependent variable and independent variables are **linear**.

#### 5.1.3.3 Test for Normality 

*ols_plot_resid_hist()* of **olsrr** package is used to perform the **normality** assumption test.

```{r echo=TRUE}
ols_plot_resid_hist(flat_mlr1)
```

The figure reveals that the residuals of the multiple linear regression model (i.e. flat_mlr1) resembles **normal distribution**.

#### 5.1.3.4 Test for Spatial Autocorrelation

The hedonic model that we are building uses **geographically referenced attributes**, hence it is also important for us to **visualise the residuals** of the hedonic pricing model.

In order to perform spatial autocorrelation test, we need to convert the `flat_resale_sf` **simple feature** object into a **SpatialPointsDataFrame**.

First, we will export the residuals of the hedonic pricing model and save it as a data frame.

```{r echo=TRUE}
mlr_output <- as.data.frame(flat_mlr1$residuals)
```

Next, we will join the newly created data frame with the `flat_resale_sf` object.

```{r echo=TRUE}
flat_resale_res_sf <- cbind(flat_resale_sf,
                            mlr_output) %>%
  rename(`MLR_RES` = `flat_mlr1.residuals`)
``` 

Next, we will convert the `flat_resale_res_sf` **simple feature** object into a **SpatialPointsDataFrame**. This is required because the **spdep** package can only process sp conformed spatial data objects.

```{r echo=TRUE}
flat_resale_sp <- as_Spatial(flat_resale_res_sf)
flat_resale_sp
```

Next, we will use tmap package to visualise the distribution of the residuals.

```{r echo=TRUE}
tmap_mode("view")

tm_shape(mpsz_sf)+
  tm_polygons(alpha = 0.4) +
tm_shape(flat_resale_res_sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

The figure above reveals that there are **signs of spatial autocorrelation**. To prove that our observation is true, the **Moran’s I test** will be performed.

First, we will compute the distance-based weight matrix by using *dnearneigh()* function of **spdep**.

```{r echo=TRUE}
nb <- dnearneigh(coordinates(flat_resale_sp), 0, 1500, longlat = FALSE)

summary(nb)
```

Next, *nb2listw()* of **spdep** packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.

```{r echo=TRUE}
nb_lw <- nb2listw(nb, style = 'W')

summary(nb_lw)
```

Next, *lm.morantest()* of **spdep** package will be used to perform Moran’s I test for residual spatial autocorrelation

```{r echo=TRUE}
lm.morantest(flat_mlr1, nb_lw)
```

The Global Moran’s I test for residual spatial autocorrelation shows that its **p-value is less than the alpha value of 0.05**. We will thus **reject** the null hypothesis that the residuals are randomly distributed.

Since the Observed Global Moran I = 0.471 which is **greater than 0**, we can infer than the residuals resemble **cluster distribution**.

## 5.2 GWR Model Method

We will calibrate the GWR-based hedonic pricing model using the adaptive bandwidth approach.

### 5.2.1 Computing the adaptive bandwidth

We first use *bw.gwr()* to determine the recommended data point to use.

```{r echo=TRUE}
bw_adaptive <- bw.gwr(formula = PRICE ~ AREA_SQM + LEASE_YRS + PROX_EC +
                      PROX_HA + PROX_MRT  + PROX_GDPRI + PROX_MALL + PROX_SUP +
                      NUM_KIN + NUM_CC + NUM_STOP + NUM_PRI,
                      data=flat_resale_sp, approach="CV", kernel="gaussian",
                      adaptive=TRUE, longlat=FALSE)
```

The result shows that the **recommended data point** is **56**. We will then pass this value in while computing the adaptive bandwidth GWR model. 

### 5.2.2 Constructing Adaptive Bandwidth GWR Model

We can now go ahead to calibrate the GWR-based hedonic pricing model using the adaptive bandwidth and gaussian kernel.

```{r echo=TRUE}
gwr_adaptive <- gwr.basic(formula = PRICE ~ AREA_SQM + LEASE_YRS + PROX_EC +
                      PROX_HA + PROX_MRT  + PROX_GDPRI + PROX_MALL + PROX_SUP +
                      NUM_KIN + NUM_CC + NUM_STOP + NUM_PRI,
                      data=flat_resale_sp, bw=bw_adaptive, 
                      kernel = 'gaussian', adaptive=TRUE, longlat = FALSE)

gwr_adaptive
```

The report shows that the **adjusted r-square** of the **GWR** is **0.9382667** which is significantly **better** than the **global multiple linear regression model** of **0.5369**.

### 5.2.3 Visualising GWR Output

In addition to regression residuals, the output feature class table includes:

- Condition Number: evaluates **local collinearity**. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers **larger than 30** may be **unreliable**.
- Local R2: these values **range between 0.0 and 1.0** and indicate **how well the local regression model fits observed y values**. 
- Predicted: estimated (or fitted) y values computed by GWR.
- Residuals: to obtain the residual values, the fitted y values are subtracted from the observed y values
- Coefficient Standard Error: measurse the reliability of each coefficient estimate.

They are all stored in a **SpatialPointsDataFrame** or **SpatialPolygonsDataFrame** object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called **SDF** of the output list.

#### 5.2.3.1 Converting SDF into sf data frame

To visualise the fields in **SDF**, we need to first covert it into **sf** data frame.

```{r echo=TRUE}
flat_resale_sf_adaptive <- st_as_sf(gwr_adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r echo=TRUE}
gwr_adaptive_output <- as.data.frame(gwr_adaptive$SDF)

flat_resale_sf_adaptive <- cbind(flat_resale_res_sf,
                                  as.matrix(gwr_adaptive_output))

glimpse(flat_resale_sf_adaptive)
```

#### 5.2.3.2 Visualising Local R2

```{r echo=TRUE}
tmap_mode("view")

tm_shape(mpsz_sf)+
  tm_polygons(alpha = 0.1) +
tm_shape(flat_resale_sf_adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

We can observe that majority of the HDB flats have **Local R-squared values** in the range from **0.6 to 1**. This implies that **most of the HDB Resale Prices** are **explained by the GWR Model**.

# 6.0 Conclusion

To recap, we used the following factors to build the hedonic pricing model:

- Area of the unit
- Floor level
- Remaining lease
- Proximity to CBD
- Proximity to eldercare centres
- Proximity to hawker centres
- Proximity to MRT
- Proximity to parks
- Proximity to good primary schools
- Proximity to shopping malls
- Proximity to supermarkets
- No. of kindergartens within 350m
- No. of childcare centres within 350m
- No. of bus stops within 350m
- No. of primary schools within 1km

From our study, we found that the majority of these factors affect the resale prices of 4-room flats with a transaction period from 01-Jan-2019 to 30-Sep-2020. Only the factor **PROX_CBD** is not used in model building since it has high correlation with another factor **PROX_GDPRI**.

# 7.0 References

- [onemapsgapi](https://cran.r-project.org/web/packages/onemapsgapi/onemapsgapi.pdf)
- [Mall-Coordinates-Web-Scraper](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/mall_coordinates_updated.csv)
- [Geocoding Singapore Coordinates: OneMap API](https://towardsdatascience.com/geocoding-singapore-coordinates-onemap-api-3e1542bf26f7)
- [OneMap API Docs](https://www.onemap.gov.sg/docs/#introduction)
- [A Comprehensive Guide to Singapore’s SAP Schools](https://smiletutor.sg/a-comprehensive-guide-to-singapores-sap-schools/)
- [Gifted Education Programme (GEP) Schools in Singapore: Which One to Choose?](https://www.kiasuparents.com/kiasu/article/gifted-education-programme-gep-schools-in-singapore-which-one-to-choose/)