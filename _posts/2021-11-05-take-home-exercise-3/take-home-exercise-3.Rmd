---
title: "Take-home Exercise 3"
description: |
  This take home exercise aims to explain factors affecting resale prices of public housing in Singapore by building hedonic pricing models using appropriate GWR methods.
author:
  - name: Genice Goh
    url: {}
date: 11-05-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# 1.0 Introduction

Housing price is affected by a variety of factors, including global factors such as the general economy of a country or property specific factors such as structural variables related to the property and locational variables related to the neighbourhood.

Hedonic pricing model is used to examine the effect of housing factors as on property price. However, this method fails to take into consideration that spatial autocorrelation and spatial heterogeneity exist in housing transaction data, which could lead to biased results (Anselin 1998). In view of this limitation, Geographical Weighted Regression (GWR) was introduced to calibrate hedonic price models for housing.

As such, we will be building hedonic pricing models to explain factors affecting the resale prices of public housing in Singapore using appropriate GWR methods.

## 1.1 The Data 

The data sets used for this analysis include:

- Resale Flat Prices from [data.gov.sg]("https://data.gov.sg/dataset/resale-flat-prices")
- Master Plan 2014 Subzone Boundary (Web) from [data.gov.sg](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web?resource_id=1c6b586b-61ca-45a9-b704-df4c9057fbd6)
- Eldercare centres, hawker centres, parks, supermarkets, kindergartens and childcare centres extracted from SLA OneMap Service by using [onemapsgapi](https://cran.r-project.org/web/packages/onemapsgapi/index.html)
- Train Station from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html)
- Bus Stop Location from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html)
- School Directory and Information from [data.gov.sg](https://data.gov.sg/dataset/school-directory-and-information)
- Shopping Mall from [ValaryLim](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/mall_coordinates_updated.csv)

# 1.2 Installing and Loading Packages

The packages used for this analysis include:

- **sf**, **spdep**: used for handling of geospatial data
- **tidyverse** (**readr**, **ggplot2**, **dplyr**): mainly used for wrangling attribute data 
- **tmap**: used to prepare cartographic quality choropleth maps
- **coorplot**, **ggpubr**: used for multivariate data visualisation and analysis
- **olsrr**: used to build ordinary least squares regression models
- **GWmodel**: used for geospatial statistical modelling
- **httr**: used to make API calls 
- **units**, **matrixStats**: used for matrix manipulation

```{r echo=TRUE}
packages = c('olsrr', 'corrplot', 'ggpubr', 'sf', 'spdep', 'GWmodel', 'tmap', 'tidyverse', 'httr', 'units', 'matrixStats')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# 2.0 Geospatial Data

## 2.1 Importing Geospatial Data

*st_read()* of **sf** package is used to import the geospatial data, which is in **shapefile** format.

```{r echo=TRUE}
mrt_sf <- st_read(dsn="data/geospatial",
               layer="MRTLRTStnPtt")

bus_sf <- st_read(dsn="data/geospatial",
               layer="BusStop")

mpsz_sf <- st_read(dsn="data/geospatial",
               layer="MP14_SUBZONE_WEB_PL")
```

From the output message, we can see that:

- There are **185 point features** and **3 fields** in the `mrt_sf` sf data frame.
- There are **5156 point features** and **3 fields** in the `bus_sf` sf data frame.
- There are **323 multi-polygon features** and **15 fields** in the `mpsz_sf` sf data frame.
- SVY21 is the **Projected Coordinates Reference System** for the data frames. 

## 2.2 Data Preprocessing

Before we visualise the geospatial data, we will need to conduct data preprocessing to ensure that there are no invalid geometries and missing values.

### 2.2.1 Invalid Geometries

```{r echo=TRUE}
length(which(st_is_valid(mrt_sf) == FALSE))
length(which(st_is_valid(bus_sf) == FALSE))
length(which(st_is_valid(mpsz_sf) == FALSE))
```

There are **no invalid geometries** in both `mrt_sf`and `bus_sf` data frames while the `mpsz_sf` data frame contains **9 invalid geometries**. We will now proceed to remove the invalid geometries in the `mpsz_sf` data frame.

```{r echo=TRUE}
mpsz_sf <- st_make_valid(mpsz_sf)

# Check again for invalid geometries
length(which(st_is_valid(mpsz_sf) == FALSE))
```

### 2.2.2 Missing Values

```{r echo=TRUE}
mrt_sf[rowSums(is.na(mrt_sf))!=0,]
bus_sf[rowSums(is.na(bus_sf))!=0,]
mpsz_sf[rowSums(is.na(mpsz_sf))!=0,]
```

We can see that there is **1 observation with missing values** in the `bus_sf` data frame. We will remove it because another bus stop of the same **BUS_ROOF_N** is found after further data exploration.

```{r echo=TRUE, eval=TRUE}
bus_sf <- bus_sf[!rowSums(is.na(bus_sf))!=0,]

# Check again for missing values
bus_sf[rowSums(is.na(bus_sf))!=0,]
```

### 2.2.3 Duplicated Values

```{r echo=TRUE, eval=TRUE}
mrt_sf[duplicated(mrt_sf$STN_NAME),]
bus_sf[duplicated(bus_sf$BUS_STOP_N),]
mpsz_sf[duplicated(mpsz_sf$SUBZONE_C),]
```

We can observe that there are **19** and **13** **duplicated observations** in the `mrt_sf` and `bus_sf` data frames respectively, while there are none in the `mpsz_sf` data frame. We will proceed to remove the duplicated observations.

```{r echo=TRUE, eval=TRUE}
mrt_sf <- mrt_sf[!duplicated(mrt_sf$STN_NAME),]
bus_sf <- bus_sf[!duplicated(bus_sf$BUS_STOP_N),]

# Check again for duplicates
mrt_sf[duplicated(mrt_sf$STN_NAME),]
bus_sf[duplicated(bus_sf$BUS_STOP_N),]
```

## 2.3 Verify Coordinate Reference System

We will first need to retrieve the coordinate reference system for verification. *st_crs()* of **sf** package is used to do this. 

```{r echo=TRUE}
st_crs(mrt_sf)
st_crs(bus_sf)
st_crs(mpsz_sf)
```

From the output messages, we can observe that the EPSG code for the data frames is currently **9001**. This is **wrong** because the EPSG code of projection coordinate system SVY21 is supposed to be **3414**, instead of 9001. 

*st_set_crs()* of **sf** package is therefore used to assign the correct EPSG code for the data frames.

```{r echo=TRUE}
mrt_sf <- st_set_crs(mrt_sf, 3414)
bus_sf <- st_set_crs(bus_sf, 3414)
mpsz_sf <- st_set_crs(mpsz_sf, 3414)
```

We will now use *st_crs()* of **sf** package to retrieve the coordinate reference system again.

```{r echo=TRUE}
st_crs(mrt_sf)
st_crs(bus_sf)
st_crs(mpsz_sf)
```

The EPSG code is now correctly assigned for all sf data frames!!

## 2.4 Visualising Geospatial Data

It is useful to plot a map to visualise the geospatial data, so that we can easily get a preliminary look at the spatial patterns. 

```{r echo=TRUE}
tmap_mode('view')

tm_shape(mrt_sf) +
  tm_dots(col="red") +
tm_shape(bus_sf) + 
  tm_dots(col="blue")
```

```{r}
tmap_mode('plot')
```

If we look closely, we can see that there are 5 bus stops outside of Singapore's boundary (46211, 46219, 46239, 46609, 47701). As we are able to travel to and fro Johor Bahru with specific buses, there are designated bus stops located at Johor Bahru.

As such, we should remove these bus stops before proceeding with our analysis. 

## 2.5 Further Data Preprocessing

In this section, we will proceed to remove the bus stops identified earlier.

### 2.5.1 Inspect the specific bus stops

```{r echo=TRUE, eval=TRUE}
omit_bus <- list(46211, 46219, 46239, 46609, 47701)
bus_sf[bus_sf$BUS_STOP_N %in% omit_bus,]
```

We can observe that the location descriptions of these bus stops indeed indicate that they are situated in Johor Bahru. We will therefore need to remove them.

```{r echo=TRUE, eval=TRUE}
bus_sf <- bus_sf[!bus_sf$BUS_STOP_N %in% omit_bus,]

# Check again if we have removed successfully
bus_sf[bus_sf$BUS_STOP_N %in% omit_bus,]
```

# 3.0 Aspatial Data

## 3.1 Obtaining Aspatial Data

We will be making use of the package [**onemapsgapi**](https://cran.r-project.org/web/packages/onemapsgapi/onemapsgapi.pdf) to query the required data sets from OneMap API. We will then save these data sets in CSV format. 

```{r echo=TRUE, eval=FALSE}
library(onemapsgapi)

token <- "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOjc5NTUsInVzZXJfaWQiOjc5NTUsImVtYWlsIjoiZ2VuaWNlLmdvaC4yMDE4QHNjaXMuc211LmVkdS5zZyIsImZvcmV2ZXIiOmZhbHNlLCJpc3MiOiJodHRwOlwvXC9vbTIuZGZlLm9uZW1hcC5zZ1wvYXBpXC92MlwvdXNlclwvc2Vzc2lvbiIsImlhdCI6MTYzNTU3OTEzMywiZXhwIjoxNjM2MDExMTMzLCJuYmYiOjE2MzU1NzkxMzMsImp0aSI6ImIzZmEyOTg1MDQyZTFiOGY0MWYzMWJlNzFmYzdlZTEwIn0.z2gh5tK3ezz0lUXLoPilPVOfN0MaXJm4N4RbAtVIQFI"

data <- list("eldercare", "hawkercentre", "relaxsg", "supermarkets", "kindergartens", "childcare")

for (d in data) {
  df <- get_theme(token, d)
  write_csv(df, str_replace("data/aspatial/df.csv", "df", d))
}
```

## 3.2 Importing Aspatial Data

*read_csv()* of **readr** package is used to import the CSV files. The outputs are **tibble** data frames. 

```{r echo=TRUE, eval=FALSE}
eldercare = read_csv("data/aspatial/eldercare.csv")
hawker = read_csv("data/aspatial/hawkercentre.csv")
park = read_csv("data/aspatial/relaxsg.csv")
supermarket = read_csv("data/aspatial/supermarkets.csv")
kindergarten = read_csv("data/aspatial/kindergartens.csv")
childcare = read_csv("data/aspatial/childcare.csv")
school = read_csv("data/aspatial/schools.csv")
mall = read_csv("data/aspatial/shopping-mall.csv")
flat_resale = read_csv("data/aspatial/resale-flat-prices.csv")
```

It is also important to understand the data that we are working with. *glimpse()* of **dplyr** package is therefore used to perform exploratory data analysis. 

```{r echo=TRUE, eval=FALSE}
glimpse(eldercare)
glimpse(hawker)
glimpse(park)
glimpse(supermarket)
glimpse(kindergarten)
glimpse(childcare)
glimpse(school)
glimpse(mall)
glimpse(flat_resale)
```

## 3.3 Data Preparation

We will proceed to prepare the data such that they can be used later for the preparation of independent variables. The steps taken include:

- Removing redundant columns (if necessary)
- Filtering the data according to specified conditions (if necessary)
- Creation of new data frames (if necessary)

```{r echo=TRUE, eval=FALSE}
# remove redundant columns for eldercare dataset
eldercare <- eldercare %>%
  select(c(1, 4:5))

# remove redundant columns for hawker dataset
hawker <- hawker %>%
  select(c(1, 14:15))

# remove redundant columns for park dataset
park <- park %>%
  select(c(1, 8:9))

# remove redundant columns for supermarket dataset
supermarket <- supermarket %>%
  select(c(1, 7:8))

# remove redundant columns for kindergarten dataset
kindergarten <- kindergarten %>%
  select(c(1, 5:6))

# remove redundant columns for childcare dataset
childcare <- childcare %>%
  select(c(1, 5:6))

# filter out primary schools; remove redundant columns 
prischool <- school %>%
  filter(mainlevel_code == "PRIMARY") %>% 
  select(c(1, 3:4, 25,27))

# filter out 4-room flats with transaction period from 01-Jan-19 to 30-Sep-20
flat_resale <- flat_resale %>% 
  filter(flat_type == "4 ROOM") %>%
  filter(month >= "2019-01" & month < "2020-10")
```

## 3.4 Data Preprocessing

We will need to conduct data preprocessing to ensure that there are no NA values in all data frames.

### 3.4.1 NA Values

```{r echo=TRUE, eval=FALSE}
eldercare[rowSums(is.na(eldercare))!=0,]
hawker[rowSums(is.na(hawker))!=0,]
park[rowSums(is.na(park))!=0,]
supermarket[rowSums(is.na(supermarket))!=0,]
kindergarten[rowSums(is.na(kindergarten))!=0,]
childcare[rowSums(is.na(childcare))!=0,]
prischool[rowSums(is.na(prischool))!=0,]
mall[rowSums(is.na(mall))!=0,]
flat_resale[rowSums(is.na(flat_resale))!=0,]
```

There are no NA values in all the data frames. 

## 3.5 Geocoding for Aspatial Data

After exploratory data analysis performed earlier, it is found that `prischool` and `flat_resale` data frames do not have **Lat** and **Lng** columns. These columns are required for the preparation of the independent variables later. We therefore need to use [OneMap API](https://cran.r-project.org/web/packages/onemapsgapi/index.html) to geocode the coordinates columns. 

### 3.5.1 Create Address Column

We first need to create an address column for the `flat_resale` data frame since the address data is currently split into 2 columns block and street name respectively.

*unite()* of **dpylr** package is used to concatenate the 2 columns. 

```{r echo=TRUE, eval=FALSE}
flat_resale <- flat_resale %>%
  unite("address", block:street_name, sep= " ")
```

### 3.5.2 Rename ST. to SAINT

We alo observe that some addresses in the the `flat_resale` data frame start with **"ST."**. It is found later that this will pose problems during geocoding. As a result, we will need to rename **"ST."** to its full version **"SAINT"**.

```{r echo=TRUE, eval=FALSE}
flat_resale$address <- gsub("ST\\.", "SAINT", flat_resale$address)
```

### 3.5.3 Geocoding Function

In this function, the input variable **address** is passed in as a search value in the query to the API. The output is then converted to a data frame, where we only choose to retain the **Latitude** and **Longitude** columns. These 2 columns are returned as the output.  

```{r echo=TRUE, eval=FALSE}
geocode <- function(address) {

  url <- "https://developers.onemap.sg/commonapi/search"

  query <- list("searchVal" = address, "returnGeom" = "Y",
                "getAddrDetails" = "N", "pageNum" = "1")

  res <- GET(url, query = query, verbose())

  output <- content(res) %>%
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

### 3.5.4 Geocoding for Primary Schools

We will now loop through each row of the `prischool` data frame and implement the **geocode** function. The output is saved as 2 new columns **Lat** and **Lng**.

```{r echo=TRUE, eval=FALSE}
prischool$Lat <- 0
prischool$Lng <- 0

for (i in 1:nrow(prischool)) {
  output <- geocode(prischool$postal_code[i])
  
  prischool$Lat[i] <- output$results.LATITUDE
  prischool$Lng[i] <- output$results.LONGITUDE
}
```

### 3.5.5 Geocoding for Resale Flat Prices

We will now loop through each row of the `flat_resale` data frame and implement the **geocode** function. The output is saved as 2 new columns **Lat** and **Lng**.

```{r echo=TRUE, eval=FALSE}
flat_resale$Lat <- 0
flat_resale$Lng <- 0

for (i in 1:nrow(flat_resale)) {
  output <- geocode(flat_resale$address[i])
  
  flat_resale$Lat[i] <- output$results.LATITUDE
  flat_resale$Lng[i] <- output$results.LONGITUDE
}
```

## 3.6 Structural Factor Preparation

### 3.6.1 Floor Level

We need to conduct dummy coding on the **storey_range** variable for us to use it in model later. We will first look at the individual storey-range values for us to get a rough idea on the number of columns that will be produced. 

```{r echo=TRUE, eval=FALSE}
unique(flat_resale$storey_range)
```

We observed that there are **17 storey range categories**.

To conduct dummy coding, we will be using *pivot_wider()* of **dplyr** package to create duplicate variables representing every store-range. If the obeservation belongs to the storey-range, the value will be 1. The value will be 0 otherwise.   

```{r echo=TRUE, eval=FALSE}
flat_resale <- flat_resale %>%
  pivot_wider(names_from = storey_range, values_from = storey_range, 
              values_fn = list(storey_range = ~1), values_fill = 0) 
```

### 3.6.2 Remaining Lease

We need to convert the **remaining_lease** column from string to numeric format to use in the model later. We will first split the string within the column and take the value(s) of the year and month. We will then calculate the remaining lease in years and replace the original value. 

```{r echo=TRUE, eval=FALSE}
str_list <- str_split(flat_resale$remaining_lease, " ")

for (i in 1:length(str_list)) {
  if (length(unlist(str_list[i])) > 2) {
      year <- as.numeric(unlist(str_list[i])[1])
      month <- as.numeric(unlist(str_list[i])[3])
      flat_resale$remaining_lease[i] <- year + round(month/12, 2)
  }
  else {
    year <- as.numeric(unlist(str_list[i])[1])
    flat_resale$remaining_lease[i] <- year
  }
}
```

## 3.7 Locational Variable Preparation

### 3.7.1 Good Pri Sch Variable Preparation

We need to filter out good primary schools and save it as variable **goodprischool** for it to be used in the model. Good primary schools are defined to be Special Assistance Programme (SAP) primary schools or primary schools with the Gifted Education Programme (GEP). 

```{r echo=TRUE, eval=FALSE}
gdprischool <- prischool %>%
  filter(sap_ind == "Yes" | gifted_ind == "Yes")
```

### 3.7.2 CBD Variable Preparation

The Central Business District (CBD) is in Downtown Core, located in the southwest part of Singapore. We will therefore take the coordinates of Downtown Core to be the coordinates of the CBD and convert it into a **sf** data frame.

```{r echo=TRUE, eval=FALSE}
lat <- 1.287953
long <- 103.851784

cbd_sf <- data.frame(lat, long) %>%
  st_as_sf(coords = c("long", "lat"), crs=4326) %>%
  st_transform(crs=3414)
```

### 3.7.3 Convert Datasets to sf

We need to convert the data sets into **sf** data frames for us to calculate the proximity distance matrices. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- st_as_sf(flat_resale, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

eldercare_sf <- st_as_sf(eldercare, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

hawker_sf <- st_as_sf(hawker, 
                      coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

park_sf <- st_as_sf(park, 
                    coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

gdprischool_sf <- st_as_sf(gdprischool, 
                           coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

mall_sf <- st_as_sf(mall, 
                    coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs = 3414)

supermarket_sf <- st_as_sf(supermarket, 
                           coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

kindergarten_sf <- st_as_sf(kindergarten, 
                            coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

childcare_sf <- st_as_sf(childcare, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)

prischool_sf <- st_as_sf(prischool, 
                         coords = c("Lng", "Lat"), crs=4326) %>%
  st_transform(crs = 3414)
```

### 3.7.4 Proximity Distance Calculation

This function computes the distance to the nearest facility. *st_distance()* of **sf** package is used to compute the distance between all flats and the respective facilities. *rowMins()* of **matrixStats** is then used to take the shortest distance within each row in the output matrix. The values will be appended to the data frame as a new column. 
  
```{r echo=TRUE, eval=FALSE}
proximity <- function(df1, df2, varname) {
  
  matrix <- st_distance(df1, df2) %>%
    drop_units()
  
  df1[,varname] <- rowMins(matrix)
  
  return(df1)
}
```

We will now implement the **proximity** function to the required variables. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- proximity(flat_resale_sf, cbd_sf, "PROX_CBD") %>%
  proximity(., eldercare_sf, "PROX_EC") %>%
  proximity(., hawker_sf, "PROX_HA") %>%
  proximity(., mrt_sf, "PROX_MRT") %>%
  proximity(., park_sf, "PROX_PARK") %>%
  proximity(., gdprischool_sf, "PROX_GDPRI") %>%
  proximity(., mall_sf, "PROX_MALL") %>%
  proximity(., supermarket_sf, "PROX_SUP")
```

### 3.7.5 Facility Count within Radius Calculation

This function computes the facility count within a radius. Similarly, *st_distance()* of **sf** package is used to compute the distance between all flats and the respective facilities. *rowSums()* of **dplyr** is then used to count the observations with distances below the defined radius. The values will be appended to the data frame as a new column. 

```{r echo=TRUE, eval=FALSE}
num_radius <- function(df1, df2, varname, radius) {
  
  matrix <- st_distance(df1, df2) %>%
    drop_units() %>%
    as.data.frame()
  
  df1[,varname] <- rowSums(matrix <= radius)
  
  return(df1)
}
```

We will now implement the **num_radius** function to the required variables. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- num_radius(flat_resale_sf, kindergarten_sf, 
                             "NUM_KIN", 350) %>%
  num_radius(., childcare_sf, "NUM_CC", 350) %>%
  num_radius(., bus_sf, "NUM_STOP", 350) %>%
  num_radius(., prischool_sf, "NUM_PRI", 1000)
```

## 3.8 Saving the Dataset

Before saving the dataset, we will remove the redundant columns, rename the columns to shorter forms and relocate the **price** columns to the front of the data frame. 

```{r echo=TRUE, eval=FALSE}
flat_resale_sf <- flat_resale_sf %>%
  select(5, 8, 9, 10:39) %>%
  rename("AREA_SQM" = "floor_area_sqm", "LEASE_YRS" = "remaining_lease", 
         "PRICE"= "resale_price") %>%
  relocate(`PRICE`)
```

We can now save the final flat resale price data set as a **SHP** file using *st_write* of **sf** package.

```{r echo=TRUE, eval=FALSE}
st_write(flat_resale_sf, "data/geospatial/resale-flat-prices-final.shp")
```

# 4.0 EDA

## 4.1 Import Full Dataset

*st_read()* of **sf** package is used to import the final data set, which is in **shapefile** format.

```{r echo=TRUE}
flat_resale_sf <- st_read(dsn="data/geospatial",
                          layer="resale-flat-prices-final")
```

## 4.2 EDA using statistical graphs

### 4.2.1 Dependent Variable 

We can plot the distribution of **PRICE** using a histogram as shown below.

```{r echo=TRUE}
ggplot(data=flat_resale_sf, aes(x=`PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

The figure above reveals a slightly **right skewed** distribution. This means that more HDB flats were transacted at **relative lower prices**.

Statistically, the skewed distribution can be **normalised** using **log transformation**. *mutate()* of **dplyr** package is used to derive a new variable called **LOG_PRICE** using a log transformation on the variable **PRICE**.

```{r echo=TRUE}
flat_resale_sf <- flat_resale_sf %>%
  mutate(`LOG_PRICE` = log(PRICE)) %>%
  relocate(`LOG_PRICE`, .after = `PRICE`)
```

We can now plot the distribution of **LOG_PRICE**.

```{r echo=TRUE}
ggplot(data=flat_resale_sf, aes(x=`LOG_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

### 4.2.2 Independent Variables

It is found that the **LEASE_YRS** column is still in string format. We will convert it to numeric format for us to conduct EDA and to input into the model later. 

```{r echo=TRUE}
flat_resale_sf$LEASE_YRS <- as.numeric(flat_resale_sf$LEASE_YRS)
```

We will now draw multiple histograms to show multiple distributions of the independent variables. This is done using *ggarrange()* of **ggpubr** package.

```{r echo=TRUE, fig.width=10, fig.height=8}
AREA_SQM <- ggplot(data=flat_resale_sf, aes(x= `AREA_SQM`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

LEASE_YRS <- ggplot(data=flat_resale_sf, aes(x= `LEASE_YRS`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=flat_resale_sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_EC <- ggplot(data=flat_resale_sf, aes(x= `PROX_EC`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER <- ggplot(data=flat_resale_sf, aes(x= `PROX_HA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=flat_resale_sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=flat_resale_sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_GDPRI <- ggplot(data=flat_resale_sf, aes(x= `PROX_GDPRI`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MALL <- ggplot(data=flat_resale_sf, aes(x= `PROX_MALL`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_SUP <- ggplot(data=flat_resale_sf, aes(x= `PROX_SUP`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_KIN <- ggplot(data=flat_resale_sf, aes(x= `NUM_KIN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_CC <- ggplot(data=flat_resale_sf, aes(x= `NUM_CC`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_STOP <- ggplot(data=flat_resale_sf, aes(x= `NUM_STOP`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_PRI <- ggplot(data=flat_resale_sf, aes(x= `NUM_PRI`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, LEASE_YRS, PROX_CBD, PROX_EC, PROX_HAWKER, PROX_MRT, PROX_PARK, PROX_GDPRI, PROX_MALL, PROX_SUP, NUM_KIN, NUM_CC, NUM_STOP, NUM_PRI, ncol = 3, nrow = 5)
```

We can observe that the distribution of the **majority** of the independent variables are **right skewed**, while variables such as **LEASE_YRS** and **PROX_CBD** are slightly **left skewed**.

## 4.3 EDA using statistical point map

We want to reveal the geospatial distribution flat resale prices (i.e. **dependent** variable) in Singapore using the **tmap** package.

```{r echo=TRUE}
tmap_mode("view")

tm_shape(mpsz_sf)+
  tm_polygons() +
tm_shape(flat_resale_sf) +  
  tm_dots(col = "PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode('plot')
```

From the map, we can observe that flats with **higher resale prices** are **more concentrated in the central area** of Singapore. 


