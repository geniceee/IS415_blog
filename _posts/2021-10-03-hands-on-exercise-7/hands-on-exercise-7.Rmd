---
title: "Hands-on Exercise 7"
description: |
  In this hands-on exercise, we learn how to compute Global and Local Measures of Spatial Autocorrelation by using spdep package.
author:
  - name: Genice Goh
    url: {}
date: 09-27-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## The Analytical Question

In spatial policy, one of the main development objective of the local government is to ensure equal distribution of development in the province. Our task in this study is therefore to apply appropriate spatial statistical methods to discover if development is evenly distributed geographically. 

If the answer is **no**, we will next question if there are **signs of spatial clustering**. If **yes**, we will then quesion the **location** of these clusters.

In this case study, we are interested to examine the spatial patterns of a selected development indicator (i.e. GDP per capita) in Hunan Province, People Republic of China.

## Installing and Loading Packages

The following packages will be used for this analysis:

- sf: used for importing and handling geospatial data
- tidyverse: mainly used for wrangling attribute data 
- spdep: used to compute spatial weights, global and local spatial autocorrelation statistics
- tmap: used to prepare cartographic quality chropleth map

```{r echo=TRUE}
packages = c('sf', 'spdep', 'tmap', 'tidyverse')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

## Importing Data

*st_read()* of **sf** package to import `Hunan` shapefile. The imported shapefile will be a **simple features** Object of **sf**.

```{r echo=TRUE}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

Next, we will import `Hunan_2012.csv` using *read_csv()* of **readr** package. The output is **R data frame class**.

```{r echo=TRUE}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## Performing Relational Join

*left_join()* of **dplyr** package is used to update the attribute table of `hunan`’s SpatialPolygonsDataFrame with the attribute fields of `hunan2012` data frame.

```{r echo=TRUE}
hunan <- left_join(hunan,hunan2012)
```

## Visualising Regional Development Indicator

We are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using *qtm()* of **tmap** package.

```{r echo=TRUE, fig.width=12, fig.height=8}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

## Global Spatial Autocorrelation

In this section, we will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.

## Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct the spatial weights of the study area. The spatial weights are used to define the neighbourhood relationships between the geographical units (i.e. counties) in the study area.

*poly2nb()* of **spdep** package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. 

We can pass a “queen” argument that takes values `TRUE` (default) or `FALSE`. If we don’t specify queen = `FALSE`, this function will return a list of **first order neighbours** using the **Queen** criteria.

The code chunk below is used to compute Queen contiguity weight matrix.

```{r echo=TRUE}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are **88 area units** in Hunan. The **most connected** area unit has **11 neighbours**. There are **two area units** with only **1 neighbour**.

### Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each **neighboring polygon** will be assigned **equal weight** (style=“W”). This is accomplished by assigning the fraction **1/(#ofneighbors)** to each neighboring county then **summing the weighted income values**.

It has a **drawback**: polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially **over-** or **under-estimating** the true nature of the spatial autocorrelation in the data.

Note: There are other more robust options are available, notably style=“B”.

```{r echo=TRUE}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

The input of *nb2listw()* must be an object of class **nb**. The syntax of the function has two major arguments, namely **style** and **zero.policy**.

- **Style** can take values “W”, “B”, “C”, “U”, “minmax” and “S”:
  - B: basic binary coding
  - W: row standardised (sums over all links to n) 
  - C: globally standardised (sums over all links to n)
  - U: equal to C divided by no. of neighbours (sums over all links to unity) 
  - S: variance-stabilizing coding scheme proposed by Tiefelsdorf et al.(sums over all links to n)

If zero.policy=`TRUE`, weights vectors of **zero length** are inserted for regions without neighbours in the neighbours list. This will in turn generate **lag values of zero**. The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

## Global Spatial Autocorrelation: Moran’s I

In this section, we learn how to perform Moran’s I statistics testing using *moran.test()* of **spdep**.

### Maron’s I test

*moran.test()* of **spdep** is used to performs Moran’s I statistical test.

```{r echo=TRUE}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```
Question: What statistical conclusion can you draw from the output above?

- The p-value is 1.095e-06, which is very small.
- We will **reject** the null hypothesis at 99.9% confidence level as the p-value is smaller than our alpha value. 
- Since the Moran I statistic 0.301 is > 0 and is approaching 1, we can infer that spatial patterns that we observed resemble a **cluster**.

**Note**: 

- When we accept or reject the null hypothesis, we have to mention at what confidence interval. 
- Once you select a confidence interval, it will translate into the alpha/ significance value.
- Confidence intervals:
  - 90%: alpha value is 0.1, no. of simulations: 100
  - 95 %: alpha value 0.05, 
  - 99 %: alpha value 0.01, 
  - 99.9: alpha value is 0.001 , no. of simulations: 1000
- We will never define the confidence level in the code but we will just define it ourselves.

### Computing Monte Carlo Moran’s I

*moran.mc()* of **spdep** is used to perform permutation test for Moran’s I statistic test. A total of 1000 simulation will be performed.

```{r echo=TRUE}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```
Question: What statistical conclusion can you draw from the output above?

- We will **accept** the null hypothesis at 99.9% as the p-value is equal to  our alpha value 0.001. 
- Since the Monte Carlo statistic 0.30075 is > 0 and is approaching 1 which is positive autocorrelation, we can infer that spatial patterns that we observed resemble a **cluster**.

### Visualising Monte Carlo Moran’s I

It is always a good practice for us the examine the simulated Moran’s I test statistics. This can be achieved by plotting the distribution of the statistical values as a histogram. *hist()* and *abline()* of **R Graphics** are used.

```{r echo=TRUE}
mean(bperm$res[1:999])
var(bperm$res[1:999])
summary(bperm$res[1:999])
```

```{r echo=TRUE}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

We can observe that the distribution of the results of the simulated Moran’s I test is right skewed.

```{r echo=TRUE}
ggplot(data=as.data.frame(bperm$res), 
       aes(x= as.numeric(`bperm$res`)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="lightblue") +
  geom_vline(aes(xintercept=0),
            color="black", linetype="dashed", size=1) +
  labs(title = "Distribution of Monte Carlo Moran’s I statistics",
      x = "Simulated Moran's I",
      y = "Frequency")
```

## Global Spatial Autocorrelation: Geary’s

In this section, we learn how to perform Geary’s c statistics testing by using appropriate functions of **spdep** package.

### Geary’s C test

*geary.test()* of **spdep** is used to perform Geary’s C test for spatial autocorrelation.

```{r echo=TRUE}
geary.test(hunan$GDPPC, listw=rswm_q)
```

Question: What statistical conclusion can you draw from the output above?

- We will **reject** the null hypothesis at 99.9% confidence level as the p-value is smaller than our alpha value of 0.0001526. 
- Since the Geary C statistic 0.691 is < 1, we can infer that spatial patterns are **clustered**.

### Computing Monte Carlo Geary’s C

*geary.mc()* of **spdep** is used to perform permutation test for Geary’s C statistic.

```{r echo=TRUE}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```

- We will **accept** the null hypothesis at 99.9% as the p-value is equal to  our alpha value 0.001. 
- Since the Monte Carlo statistic 0.691 is < 1, we can infer that spatial patterns are **clustered**.

### Visualising the Monte Carlo Geary’s C

We will next plot a histogram to reveal the distribution of the simulated values.

```{r echo=TRUE}
mean(bperm$res[1:999])
var(bperm$res[1:999])
summary(bperm$res[1:999])
```

```{r echo=TRUE}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```

We can observe that the distribution of the results of the simulated Geary's C test looks to be normal.

## Spatial Correlogram

Spatial correlograms are great to examine **patterns of spatial autocorrelation** in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.

Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very **useful** as an **exploratory and descriptive tool**. For this purpose they actually provide richer information than variograms.

### Compute Moran’s I correlogram

*sp.correlogram()* of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I. *plot()* of **base Graph** is then used to plot the output.

```{r echo=TRUE}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

The plotted output might not provide complete interpretation. This is because not all autocorrelation values are statistically significant. It is therefore important for us to examine the full analysis report.

```{r echo=TRUE}
print(MI_corr)
```
Question: What statistical observation can you draw from the plot above? 

- For lag 4, we don't have enough statistical evidence to reject the null hypothesis because the p value is greater than the alpha value of 0.001.
- For the rest of the lags, we can reject the null hypothesis because the respective p values are smaller than the alpha values of 0.001.
- Since the Moran I statistics for lags 1-4 are > 0, we can infer that their spatial patterns are **clustered**.
- On the other hand, the Moran I statistics for lags 5-6 are < 0, we can therefore infer that their spatial patterns are **dispersed**.

### Compute Geary’s C correlogram and plot

*sp.correlogram()* of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Geary’s C. *plot()* of **base Graph** is then used to plot the output.

```{r echo=TRUE}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```
Similarly, we will print out the analysis report.

```{r echo=TRUE}
print(GC_corr)
```

Question: What statistical observation can you draw from the plot above? 

- For lags 3, 4 and 6, we don't have enough statistical evidence to reject the null hypothesis because the respective p values are greater than the alpha value of 0.001.
- For lags 1, 2 and 5, we can reject the null hypothesis because the respective p values are smaller than the alpha values of 0.001.
- Since the Geary C statistics for lags 1-3 are < 1, we can infer that their spatial patterns are **clustered**.
- On the other hand, the Geary C statistics for lag 4-6 are > 1, we can therefore infer that their spatial patterns are **dispersed**.

## Cluster and Outlier Analysis

LISA (Local Indicators of Spatial Association) are statistics that evaluate the **existence of clusters** in the spatial arrangement of a given variable. 

E.g. If we are studying *cancer rates* among census tracts in a given city:

- Local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone
- This means the values occurring are above or below those of a random distribution in space.

In this section, we learn how to apply appropriate LISA, especially local Moran’I to detect clusters and/or outliers from GDP per capita 2012 of Hunan Province, PRC.

### Computing local Moran’s I

*localmoran()* of **spdep** package will be used to compute local Moran’s I of GDPPC2012 at the county level. 

It computes *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

```{r echo=TRUE}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

*localmoran()* function returns a matrix of values whose columns are:

- Ii: local Moran’s I statistics
- E.Ii: expectation of local Moran's I statistic under the randomisation hypothesis
- Var.Ii: variance of local Moran's I statistic under the randomisation hypothesis
- Z.Ii: standard deviation of local Moran's I statistic
- Pr(): p-value of local moran statistic

We will now list the content of the local Moran matrix derived using *printCoefmat()*.

```{r echo=TRUE}
printCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)
```

## Mapping local Moran’s I

Before plotting the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. `localMI`) to the `hunan` SpatialPolygonDataFrame. The output SpatialPolygonDataFrame is called `hunan.localMI`.

```{r echo=TRUE}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

### Mapping local Moran’s I values

Using choropleth mapping functions of tmap package, we can plot the local Moran’s I values.

```{r echo=TRUE, fig.width=8, fig.height=6}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

### Mapping local Moran’s I p-values

The choropleth map above shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values.

The choropleth mapping functions of tmap package is again used to plot the local Moran’s I p-values.

```{r echo=TRUE, fig.width=8, fig.height=6}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

### Mapping both local Moran’s I values and p-values

For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

```{r echo=TRUE, fig.width=12, fig.height=8}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

## Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

### Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

*moran.plot()* of **spdep** package plots the Moran scatterplot of GDPPC 2012.

```{r echo=TRUE}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

Note that the plot is split in **4 quadrants**:
  - LH (Neg- ac, Outlier), HH (Pos+ ac, cluster)
  - LL (Pos+ ac, Cluster), HL (Neg- ac, outlier)
  - Wz is neighbour (y axis), z is you/target (x axis)

For this plot, you need to standardise it by scaling it and have both to cutoff at 0. The top right corner belongs to areas that have **high GDPPC** and are surrounded by other areas that have the average level of GDPPC. This is the **high-high** location as shown in in the lesson slides.

### Plotting Moran scatterplot with standardised variable

We will first use *scale()* to **center** and **scale** the variable. Centering is done by **subtracting the mean** (omitting NAs) the corresponding columns and scaling is done by **dividing** the (centered) variable **by their standard deviations**.

*as.vector()* is added to make sure that the data type we get out of this is a vector, that maps neatly into output dataframe.

```{r echo=TRUE}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector 
```

We are now ready to plot the Moran scatterplot again.

```{r echo=TRUE}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

Note that the plot is split in **4 quadrants**:
  - LH (Neg- ac, Outlier), HH (Pos+ ac, cluster)
  - LL (Pos+ ac, Cluster), HL (Neg- ac, outlier)
  - Wz is neighbour (y axis), z is you/target (x axis)
  
After scaling it, we can see that both is now cutoff at 0.

### Preparing LISA map classes

The code chunks below show the steps to prepare a LISA cluster map.

```{r echo=TRUE}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Next, we center the **variable of interest** around its mean.

```{r echo=TRUE}
DV <- hunan$GDPPC - mean(hunan$GDPPC)  
```

This is followed by centering the **local Moran’s** around the mean.

```{r echo=TRUE}
C_mI <- localMI[,1] - mean(localMI[,1]) 
```

Next, we will set a statistical significance level for the local Moran.

```{r echo=TRUE}
signif <- 0.05  
```

These four command lines define the high-high, low-low, low-high and high-low categories.

```{r echo=TRUE}
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
```

Lastly, we place the non-significant Moran in the category 0.

```{r echo=TRUE}
quadrant[localMI[,5]>signif] <- 0
```

### Plotting LISA map
  
```{r echo=TRUE, fig.width=8, fig.height=6}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

```{r echo=TRUE, fig.width=10, fig.height=8}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, asp=1, ncol=2)
```

Question: What statistical observations can you draw from the LISA map above?

- We should look at the map with the original values to make sense of the LISA map.
- Focusing on the Low-High cluster, the original map does not show any high values. 
- The High-High cluster is definitely correct. 
- There are issues with the Low-Low cluster as it should be a Low-High outlier.
- To do: plot a new plot with the correct classification

## Hot Spot and Cold Spot Area Analysis

Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

## Getis and Ord’s G-Statistics

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). 

It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially. Statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps:

- Deriving spatial weight matrix
- Computing Gi statistics
- Mapping Gi statistics

Note: If you have negative values, you cannot use Getis and Ord's G Stats. It must be **all positive**. Must calculate using **distance based matrix** and not contiguity matrix.

## Deriving distance-based weight matrix

First, we need to define a new set of neighbours because we need to define neighbours based on distance for Getis-Ord.

There are 2 types of distance-based proximity matrices:

- Fixed distance weight matrix
- Adaptive distance weight matrix

### Deriving the centroid

We will need points to associate with each polygon before we can make our connectivity graph and the coordinates need to be in a separate data frame for this to work.

To do this, we will use a mapping function which applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of `hunan` and we will be using *st_centroid()* of **sf** package. We will be using *map_dbl()* variation of *map()* from the **purrr** package and it returns a double vector.

To get the longitude values, we map st_centroid() over the geometry column of hunan and access it using [[1]]. This is because the longitude is the first value in each centroid.

```{r echo=TRUE}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

Similarly, we will retrieve the latitude values by accessing it using [[2]], since the latitude is the second value in each centroid.

```{r echo=TRUE}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

*cbind()* is now used to put the longitude and latitude values into the same object.

```{r echo=TRUE}
coords <- cbind(longitude, latitude)
```

### Determine the cut-off distance

Firstly, we need to determine the upper limit for distance band by using the steps below:

- Return a matrix with the indices of points belonging to the k nearest neighbours of the polygon centroids by using *knearneigh()* of **spdep**.
- Convert the **knn** object into a neighbours list of class **nb** with a list of integer vectors containing neighbour region number ids by using *knn2nb()*.
- Return the length of neighbour relationship edges by using *nbdists()* of spdep. The function returns in the units of the coordinates if they are projected, else in **km**.
- Remove the list structure of the returned object using *unlist()*.

```{r echo=TRUE}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have **at least one neighbour**.

### Computing fixed distance weight matrix

We will now compute the distance weight matrix using *dnearneigh()*.

```{r echo=TRUE}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, *nb2listw()* is used to convert the **nb** object into spatial weights object. The output spatial weights object is called `wm62_lw`.

```{r echo=TRUE}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

### Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (i.e. urban areas) tend to have more neighbours and the less densely settled areas (i.e. rural counties) tend to have less neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry.

```{r echo=TRUE}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Next, *nb2listw()* is used to convert the **nb** object into spatial weights object.

```{r echo=TRUE}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

## Computing Gi statistics

### Gi statistics using fixed distance

```{r echo=TRUE}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

The output of *localG()* is a **vector** of G or Gstar values where attributes:

- “gstari” is set to TRUE or FALSE
- “call” is set to the function call
- “class” is set to “localG”.

The Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Next, we will join the Gi values to their corresponding `hunan` sf data frame.

```{r echo=TRUE}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

The code chunk above performs three tasks:

- Converts the output vector `gi.fixed` into **r matrix** object using *as.matrix()*. 
- *cbind()* is used to join `hun@data` and `gi.fixed` matrix to produce a new **SpatialPolygonDataFrame** called hunan.gi.
- The field name of the gi values is then renamed to `gstat_fixed` by using *rename()*.

### Mapping Gi values with fixed distance weights

```{r echo=TRUE, fig.width=12, fig.height=8}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi Fixed") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

Question: What statistical observation can you draw from the Gi map above?

- Do not confuse Moran I with Gi stat
- Left side, western region is the cold spot area while the hot spot area is in the east side. 
- If you plot the transportation line, you can see that it is mainly on the east side. So this might be one of the underlying reason why the hot spot areas are on the right side. 

### Gi statistics using adaptive distance

The code chunk below is used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e `knb_lw`).

```{r echo=TRUE}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

### Mapping Gi values with adaptive distance weights

It is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.

```{r echo=TRUE, fig.width=10, fig.height=8}
gdppc <- qtm(hunan, "GDPPC")

Gimap2 <- tm_shape(hunan.gi) +
  tm_fill(col = "gstat_adaptive", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi Adaptive") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap2, asp=1, ncol=2)
```

Question: What statistical observation can you draw from the Gi map above?

- This plot with the adaptive weights is actually smoother than the previous map with fixed weights
- The range in the legend has also changed


### Plotting it altogether

```{r echo = TRUE, fig.width=10, fig.height=8}
tmap_arrange(gdppc, Gimap, Gimap2, asp=2, ncol=2)
```
